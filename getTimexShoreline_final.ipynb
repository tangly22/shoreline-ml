{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd17dee6",
   "metadata": {},
   "source": [
    "## Shoreline Extraction Image Product | [getTimexShoreline.py]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684695bf",
   "metadata": {},
   "source": [
    "## Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100d1f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T23:16:16.118542Z",
     "start_time": "2024-04-04T23:16:15.961886Z"
    }
   },
   "outputs": [],
   "source": [
    "# getStationInfo(ssPath) | return(stationInfo) - [imgProcTools.py]\n",
    "\n",
    "import cv2\n",
    "import pytz\n",
    "import termcolor\n",
    "from tqdm import trange\n",
    "from pathlib import Path\n",
    "from termcolor import cprint\n",
    "\n",
    "def getStationInfo(ssPath):\n",
    "    # Converts specific fields in the loaded stationInfo dictionary from lists to NumPy arrays.\n",
    "    setupFile = open(ssPath)\n",
    "    stationInfo = json.load(setupFile)\n",
    "    \n",
    "    stationInfo['Apx. Shoreline']['slX'] = np.asarray(stationInfo['Apx. Shoreline']['slX'])\n",
    "    stationInfo['Apx. Shoreline']['slY'] = np.asarray(stationInfo['Apx. Shoreline']['slY'])\n",
    "    \n",
    "    stationInfo['Collision Test Points']['x'] = np.asarray(stationInfo['Collision Test Points']['x'])\n",
    "    stationInfo['Collision Test Points']['y'] = np.asarray(stationInfo['Collision Test Points']['y'])\n",
    "    \n",
    "    stationInfo['Dune Line Info']['Dune Line Interpolation'] = np.asarray(stationInfo['Dune Line Info']['Dune Line Interpolation'])\n",
    "    stationInfo['Dune Line Info']['Dune Line Points'] = np.asarray(stationInfo['Dune Line Info']['Dune Line Points'])\n",
    "    \n",
    "    stationInfo['Shoreline Transects']['x'] = np.asarray(stationInfo['Shoreline Transects']['x'])\n",
    "    stationInfo['Shoreline Transects']['y'] = np.asarray(stationInfo['Shoreline Transects']['y'])\n",
    "    \n",
    "    return(stationInfo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d529d02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T23:16:17.298258Z",
     "start_time": "2024-04-04T23:16:16.120420Z"
    }
   },
   "outputs": [],
   "source": [
    "# mapROI(stationInfo, photo, imgType): | return (maskedImg, figROI) - [shorelineFunctions.py]\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from skimage.measure import profile_line\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "\n",
    "def mapROI(stationInfo, photo, imgType):\n",
    "    # Set width and height in pixels of image.\n",
    "    w = len(photo[1])\n",
    "    h = len(photo)\n",
    "    \n",
    "    # Retrieves pixel transect coordinates based on image type.\n",
    "    if imgType == 'avg' or imgType == 'brt' or imgType == 'snap':\n",
    "        transects = stationInfo['Shoreline Transects']\n",
    "        xt = np.asarray(transects['x'])\n",
    "        yt = np.asarray(transects['y'])       \n",
    "    elif imgType == 'rec':\n",
    "        transects = stationInfo['Rectified Transects']\n",
    "        xt = np.asarray(transects['x'])\n",
    "        yt = np.asarray(transects['y'])\n",
    "    \n",
    "    # Draws polygon based on transects and creates masks on unneeded areas.\n",
    "    cords = []\n",
    "    for i in range(0,len(xt)):\n",
    "        pts = [int(xt[i,1]),int(yt[i,1])]\n",
    "        cords.append(pts)\n",
    "        \n",
    "    for i in range(len(xt)-1,-1,-1):\n",
    "        pts = [int(xt[i,0]),int(yt[i,0])]\n",
    "        cords.append(pts)\n",
    "    cords.append(cords[0])\n",
    "    \n",
    "    xs, ys = zip(*cords)\n",
    "    poly = list(itertools.chain.from_iterable(cords))\n",
    "    \n",
    "    img = Image.new('L', (w, h), 0)\n",
    "    ImageDraw.Draw(img).polygon(poly, outline=1, fill=1)\n",
    "    \n",
    "    # Converts mask to a nparray.\n",
    "    if imgType == 'rec':\n",
    "        mask = np.array(np.flipud(img))\n",
    "    else:\n",
    "        mask = np.array(img)\n",
    "    \n",
    "    # Sets pixels outside of mask to NaN.\n",
    "    maskedImg = photo.astype(np.float64)\n",
    "    for i in range(0,w):\n",
    "        for j in range(0,h):\n",
    "            if mask[j,i] == 0:\n",
    "                maskedImg[j,i] = np.NaN\n",
    "            else:\n",
    "                maskedImg[j,i] = (maskedImg[j,i]/255)\n",
    "    \n",
    "    # Generates figure with mask.\n",
    "    figROI = pltFig_ROI(stationInfo, photo, maskedImg, xs, ys, imgType)\n",
    "    \n",
    "    return (maskedImg, figROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5135e95f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T23:16:17.314360Z",
     "start_time": "2024-04-04T23:16:17.299625Z"
    }
   },
   "outputs": [],
   "source": [
    "# pltFig_ROI(stationInfo, photo, maskedImg, xs, ys, imgType): | return(figROI) - [plotFigures.py]\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def pltFig_ROI(stationInfo, photo, maskedImg, xs, ys, imgType):\n",
    "        \n",
    "    # Initializes station setup.\n",
    "    stationname = stationInfo['Station Name']\n",
    "    dtInfo = stationInfo['Datetime Info']\n",
    "    date = str(dtInfo.date())\n",
    "    time = str(dtInfo.hour) + str(dtInfo.minute)\n",
    "    \n",
    "    if imgType == 'avg':\n",
    "        source = 'Time-Averaged'\n",
    "    if imgType == 'brt': \n",
    "        source = 'Brightest Pixel'\n",
    "    if imgType == 'rec':\n",
    "        source = 'Rectified Image'\n",
    "    if imgType == 'snap':\n",
    "        source = 'Snapshot'    \n",
    "    if imgType == 'avg' or imgType == 'brt' or imgType == 'snap':\n",
    "        rmb = maskedImg[:,:,0] - maskedImg[:,:,2] # transect columns\n",
    "        \n",
    "        # Plots figure for final output.\n",
    "        plt.ioff()\n",
    "        figROI, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,9))\n",
    "        ax1.imshow(photo)\n",
    "        ax1.plot(xs,ys, 'r--', label = 'ROI Boundaries') \n",
    "        ax1.set_title(('Region of Interest (ROI)'), fontsize = 14)\n",
    "        ax1.set_xlabel('Image Width (pixels)')\n",
    "        ax1.set_ylabel('Image Height (pixels)')\n",
    "        ax1.legend(prop={'size': 9}, loc=2)\n",
    "        ax1.tick_params(axis = 'both', which = 'major', labelsize = 10)\n",
    "        ax1.tick_params(axis = 'both', which = 'minor', labelsize = 10)\n",
    "        im2 = ax2.imshow(rmb, cmap=plt.get_cmap('viridis'))\n",
    "        ax2.plot(xs,ys, 'r--', label = 'ROI Boundaries') \n",
    "        ax2.set_title(('Red - Blue ROI Masking'), fontsize = 14)\n",
    "        ax2.set_xlabel('Image Width (pixels)')\n",
    "        ax2.set_ylabel('Image Height (pixels)')\n",
    "        ax2.legend(prop={'size': 9}, loc=2)\n",
    "        ax2_divider = make_axes_locatable(ax2)\n",
    "        ax2.tick_params(axis = 'both', which = 'major', labelsize = 10)\n",
    "        ax2.tick_params(axis = 'both', which = 'minor', labelsize = 10)\n",
    "        cax2 = ax2_divider.append_axes(\"right\", size=\"5%\", pad=\"2%\")\n",
    "        figROI.colorbar(im2, cax=cax2)\n",
    "        figROI.suptitle((stationname.capitalize() + ' Region of Interest\\n' \n",
    "                         ' at ' + time[:2] + ':' + time[2:] + ' UTC' + ' on ' + date + \n",
    "                         ' (' + source + ')'), fontsize = 16, y = 0.77)\n",
    "        plt.tight_layout()\n",
    "    plt.close()\n",
    "    \n",
    "    return(figROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34ee944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T23:16:17.319553Z",
     "start_time": "2024-04-04T23:16:17.316130Z"
    }
   },
   "outputs": [],
   "source": [
    "# improfile(rmb, stationInfo): | return(P) - [shorelineFunctions.py]\n",
    "\n",
    "def improfile(rmb, stationInfo):\n",
    "    \n",
    "    # Extract intensity profiles along shoreline transects from an input image.\n",
    "    transects = stationInfo['Shoreline Transects']\n",
    "    xt = np.asarray(transects['x'])\n",
    "    yt = np.asarray(transects['y'])\n",
    "  \n",
    "    n = len(xt)\n",
    "    imProf = [0]*n   \n",
    "    for i in range(0,n):\n",
    "        imProf[i] = profile_line(rmb, (yt[i,1], xt[i,1]), (yt[i,0], xt[i,0]),\n",
    "                                 mode = 'constant')\n",
    "        \n",
    "    tot = [imProf[0].tolist()]\n",
    "    \n",
    "    for i in range(0,n): \n",
    "        cvt = imProf[i].tolist()\n",
    "        tot.append(cvt)\n",
    "\n",
    "    improfile = []\n",
    "    for i in range(0,n): \n",
    "        for j in range(0, len(tot[i])):\n",
    "            if math.isnan(tot[i][j]):\n",
    "                pass\n",
    "            else:\n",
    "                improfile.append(tot[i][j])   \n",
    "            \n",
    "    P = np.asarray(improfile)  \n",
    "    \n",
    "    return(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a89ee01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T23:16:17.322650Z",
     "start_time": "2024-04-04T23:16:17.320487Z"
    }
   },
   "outputs": [],
   "source": [
    "# ksdensity(P, **kwargs): | return (pdf, x_grid) - [shorelineFunctions.py]\n",
    "\n",
    "def ksdensity(P, **kwargs):\n",
    "    # Univariate Kernel Density Estimation with Statsmodels.\n",
    "    x_grid = np.linspace(P.max(), P.min(), 1000)\n",
    "    kde = KDEUnivariate(P)\n",
    "    kde.fit(**kwargs)\n",
    "    pdf = kde.evaluate(x_grid)\n",
    "    \n",
    "    return (pdf, x_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055e9a17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T23:16:17.380323Z",
     "start_time": "2024-04-04T23:16:17.323871Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract() | return(shoreline) - [slExtract.py]\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def extract(stationInfo, rmb, maskedImg, threshInfo, imgType):\n",
    "    \n",
    "    # Defines variables.\n",
    "    stationname = stationInfo['Station Name']\n",
    "    slTransects = stationInfo['Shoreline Transects']\n",
    "    dtInfo = stationInfo['Datetime Info']\n",
    "    date = dtInfo.date()\n",
    "    xt = np.asarray(slTransects['x'])\n",
    "    yt = np.asarray(slTransects['y'])\n",
    "    orn = stationInfo['Orientation']\n",
    "    thresh = threshInfo['Thresh'] \n",
    "    thresh_otsu = threshInfo['Otsu Threshold']\n",
    "    thresh_weightings = threshInfo['Threshold Weightings']\n",
    "    length = len(yt) #- 1\n",
    "    trsct = range(0, length)\n",
    "\n",
    "    # Initializes list to store values.\n",
    "    values = [0]*length\n",
    "    revValues = [0]*length\n",
    "    yList = [0]*length\n",
    "    xList = [0]*length\n",
    "    \n",
    "    # Checks orientation.\n",
    "    if orn == 0:\n",
    "        # Finds the index of the first occurrence of\n",
    "        # a value greater than thresh_otsu in a list.\n",
    "        def find_intersect(List, thresh):\n",
    "            res = [k for k, x in enumerate(List) if x > thresh_otsu]\n",
    "            return None if res == [] else res[0]\n",
    "    \n",
    "        # Loops over each transect and extracts values from rmb \n",
    "        # array based on transect coordinates. Calculates the \n",
    "        # difference between yMax and yMin to determine the \n",
    "        # number of elements in the val list. Then populates the val list.\n",
    "        for i in trsct:\n",
    "            x = int(xt[i][0])\n",
    "            yMax = round(yt[i][1])\n",
    "            yMin = round(yt[i][0])\n",
    "            y = yMax-yMin\n",
    "            yList[i] = np.zeros(shape=y)\n",
    "            val = [0]*(yMax-yMin)\n",
    "            for j in range(0,len(val)):\n",
    "                k = yMin + j\n",
    "                val[j] = rmb[k][x]\n",
    "            val = np.array(val)\n",
    "            values[i] = val\n",
    "        \n",
    "        # Finding the index of the intersection point with the threshold value. \n",
    "        # It then calculates the x and y coordinates of the intersection point and stores.\n",
    "        intersect = [0]*len(xt)  \n",
    "        idx = [0]*len(xt) \n",
    "        Pts = [0]*len(xt) \n",
    "        xPt = [0]*len(xt)\n",
    "        yPt = [0]*len(xt)  \n",
    "        \n",
    "        for i in range(0, len(values)):\n",
    "            intersect[i] = find_intersect(values[i], thresh_otsu)\n",
    "            idx[i] = np.where(values[i][intersect[i]] == values[i])\n",
    "            n = len(idx[i][0])-1\n",
    "            if len(idx[i][0]) == 0:\n",
    "                yPt[i] = None\n",
    "                xPt[i] = None\n",
    "            else:\n",
    "               yPt[i] = min(yt[i]) + idx[i][0][n]\n",
    "               xPt[i] = int(xt[i][0])\n",
    "               Pts[i] = (xPt[i], yPt[i]) \n",
    "            \n",
    "            # Calculates the average value in a 21x21 sample area around each \n",
    "            # intersection point.\n",
    "            areaAvg = [0]*len(Pts)\n",
    "            sample = np.zeros((21,21))\n",
    "            \n",
    "            for i in range(0,len(Pts)):\n",
    "                if Pts[i] == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    orginX = int(Pts[i][0])\n",
    "                    orginY = int(Pts[i][1])\n",
    "                    xBounds = range(orginX - 10, orginX + 11)\n",
    "                    yBounds = range(orginY - 10, orginY + 11)\n",
    "                    for j in yBounds:\n",
    "                        a = j - orginY\n",
    "                        for k in xBounds:\n",
    "                            b = k - orginX\n",
    "                            sample[a][b] = rmb[j][k]\n",
    "                    areaAvg[i] = np.mean(sample)\n",
    "            \n",
    "            # Determines the points that are considered as valid shoreline \n",
    "            # points based on the average values calculated earlier. \n",
    "            # It removes points that fall outside a certain range around the threshold value.\n",
    "            # Exports shoreline variables to a JSON file. Returns the shoreline points array.\n",
    "            buffer = (float(thresh_otsu) * .20)\n",
    "            exc = {0}\n",
    "            for i in range(0,len(Pts)):\n",
    "                if abs((buffer + thresh_otsu)) > abs(areaAvg[i]) > abs((buffer - thresh_otsu)):\n",
    "                    pass\n",
    "                else:\n",
    "                    exc.add(i)\n",
    "                                            \n",
    "            truePts = [v for i, v in enumerate(Pts) if i not in exc]  \n",
    "                \n",
    "            threshX = [0]*len(truePts)\n",
    "            threshY = [0]*len(truePts)\n",
    "            for i in range(0, len(truePts)):\n",
    "                threshX[i] = truePts[i][0]\n",
    "                threshY[i] = truePts[i][1]\n",
    "             \n",
    "            threshX = np.array(threshX)\n",
    "            threshY = np.array(threshY)\n",
    "            \n",
    "            shoreline = np.vstack((threshX,threshY)).T\n",
    "\n",
    "    else:\n",
    "        # Finds the index of the first element in List less than thresh.\n",
    "        def find_intersect(List, thresh):\n",
    "            res = [k for k, x in enumerate(List) if x < thresh_otsu]\n",
    "            return None if res == [] else res[0]\n",
    "        \n",
    "        # Iterates over each transect in the list and creates array of points.\n",
    "        for i in trsct:\n",
    "            xMax = round(xt[i][0])\n",
    "            y = int(yt[i][0])\n",
    "            yList[i] = np.full(shape=xMax, fill_value= y)\n",
    "            xList[i] = np.arange(xMax)\n",
    "            values[i] =rmb[y][0:xMax]\n",
    "            revValues[i] = rmb[y][::-1]\n",
    "        \n",
    "        # Creates empty arrays.\n",
    "        intersect = [0]*len(yt)  \n",
    "        idx = [0]*len(yt) \n",
    "        Pts = [0]*len(yt) \n",
    "        xPt = [0]*len(yt)\n",
    "        yPt = [0]*len(yt)  \n",
    "        \n",
    "        # Checks revValues againts thresh_otsu.\n",
    "        for i in range(0, len(values)):\n",
    "            intersect[i] = find_intersect(revValues[i], thresh_otsu)\n",
    "            idx[i] = np.where(revValues[i][intersect[i]] == values[i])\n",
    "            n = len(idx[i][0])-1\n",
    "            if len(idx[i][0]) == 0:\n",
    "                xPt[i] = None\n",
    "                yPt[i] = None\n",
    "            else:\n",
    "               xPt[i] = idx[i][0][n]\n",
    "               yPt[i] = int(yt[i][0])\n",
    "               Pts[i] = (xPt[i], yPt[i]) \n",
    "            \n",
    "            # Computes a 21x21 pixel average around each point.\n",
    "            areaAvg = [0]*len(Pts)\n",
    "            sample = np.zeros((21,21))\n",
    "            \n",
    "            # Filters out points in buffer zone.\n",
    "            for i in range(0,len(Pts)):\n",
    "                if Pts[i] == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    orginX = Pts[i][0]\n",
    "                    orginY = Pts[i][1]\n",
    "                    xBounds = range(orginX - 10, orginX + 11)\n",
    "                    yBounds = range(orginY - 10, orginY + 11)\n",
    "                    for j in yBounds:\n",
    "                        a = j - orginY\n",
    "                        for k in xBounds:\n",
    "                            b = k - orginX\n",
    "                            sample[a][b] = rmb[j][k]\n",
    "                    areaAvg[i] = np.mean(sample)\n",
    "\n",
    "            buffer = (float(thresh_otsu) * .20)\n",
    "            exc = {0}\n",
    "            for i in range(0,len(Pts)):\n",
    "                if abs((buffer + thresh_otsu)) > abs(areaAvg[i]) > abs((buffer - thresh_otsu)):\n",
    "                    pass\n",
    "                else:\n",
    "                    exc.add(i)\n",
    "            \n",
    "            # Stores final shoreline values in an array. \n",
    "            truePts = [v for i, v in enumerate(Pts) if i not in exc]  \n",
    "            threshX = [0]*len(truePts)\n",
    "            threshY = [0]*len(truePts)\n",
    "            for i in range(0, len(truePts)):\n",
    "                threshX[i] = truePts[i][0]\n",
    "                threshY[i] = truePts[i][1]\n",
    "            threshX = np.array(threshX)\n",
    "            threshY = np.array(threshY)\n",
    "            shoreline = np.vstack((threshX,threshY)).T\n",
    "            \n",
    "    # Contructs dictionary of shoreline variables.\n",
    "    slVars = {\n",
    "        'Station Name':stationname, \n",
    "        'Date':str(date), \n",
    "        'Time Info':str(dtInfo), \n",
    "        'Thresh':thresh, \n",
    "        'Otsu Threshold':thresh_otsu,\n",
    "        'Shoreline Transects': slTransects,\n",
    "        'Threshold Weightings':thresh_weightings,\n",
    "        'Shoreline Points':shoreline\n",
    "        }\n",
    "    \n",
    "    # Converts numpy arrays to lists and removes non-serializable objects for JSON.\n",
    "    # datetime and ndarray\n",
    "    try:\n",
    "        del slVars['Time Info']['DateTime Object (UTC)']\n",
    "        del slVars['Time Info']['DateTime Object (LT)']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if type(slVars['Shoreline Transects']['x']) == np.ndarray:\n",
    "        slVars['Shoreline Transects']['x'] = slVars['Shoreline Transects']['x'].tolist()\n",
    "        slVars['Shoreline Transects']['y'] = slVars['Shoreline Transects']['y'].tolist()\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    slVars['Shoreline Points'] = slVars['Shoreline Points'].tolist()\n",
    "    \n",
    "    # Export shoreline variables to JSON.\n",
    "    fname = (stationname + '.' + datetime.strftime(dtInfo,'%Y-%m-%d_%H%M') + '.' + imgType + '.slVars.json')\n",
    "    with open(fname, \"w\") as f:\n",
    "        json.dump(slVars, f)\n",
    "            \n",
    "    return(shoreline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c37883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T23:16:17.386688Z",
     "start_time": "2024-04-04T23:16:17.381515Z"
    }
   },
   "outputs": [],
   "source": [
    "# pltFig_tranSL(stationInfo, photo, tranSL, imgType): | return(fig_tranSL) - [plotFigures.py]\n",
    "\n",
    "def pltFig_tranSL(stationInfo, photo, tranSL, imgType):\n",
    "    \n",
    "    # Initializes station setup.\n",
    "    stationname = stationInfo['Station Name']\n",
    "    dtInfo = stationInfo['Datetime Info']\n",
    "    date = str(dtInfo.date())\n",
    "    time = str(dtInfo.hour) + str(dtInfo.minute)\n",
    "    \n",
    "    # Uncomment to plot test points.\n",
    "    # tst = stationInfo['Collision Test Points']\n",
    "    # tstX = tst['x']\n",
    "    # tstY = tst['y']\n",
    "    \n",
    "    # Sets up dune line for plotting.\n",
    "    Di = stationInfo['Dune Line Info']\n",
    "    orn = stationInfo['Orientation']\n",
    "    if orn == 0:\n",
    "        duneInt = Di['Dune Line Interpolation']\n",
    "        xi = duneInt[:,0]\n",
    "        py = duneInt[:,1]    \n",
    "    else:\n",
    "        duneInt = Di['Dune Line Interpolation']\n",
    "        xi = duneInt[:,0]\n",
    "        py = duneInt[:,1]\n",
    "    \n",
    "    # Plots shoreline.\n",
    "    plt.ioff()\n",
    "    fig_tranSL = plt.figure()\n",
    "    plt.imshow(photo, interpolation = 'nearest')\n",
    "    plt.xlabel(\"Image Width (pixels)\", fontsize = 10)\n",
    "    plt.ylabel(\"Image Height (pixels)\", fontsize = 10)\n",
    "    plt.tick_params(axis = 'both', which = 'major', labelsize = 8)\n",
    "    plt.tick_params(axis = 'both', which = 'minor', labelsize = 8)\n",
    "    plt.plot(tranSL[:,0], tranSL[:,1], color = 'r', linewidth = 2, \n",
    "         label = 'Detected Shoreline')\n",
    "    plt.plot(xi, py, color = 'blue', linewidth = 2, label = 'Baseline', \n",
    "         zorder = 4)  \n",
    " \n",
    "    # Uncomment to plot test points.\n",
    "     # plt.scatter(tstX[:-2], tstY[:-2], 3, color = 'lime', linewidths = 0.5,\n",
    "               # label = 'Test Points', edgecolors ='k', zorder = 10 )\n",
    "    \n",
    "    if imgType == 'avg':\n",
    "        source = 'Time Averaged'\n",
    "    if imgType == 'brt': \n",
    "        source = 'Brightest Pixel'\n",
    "    if imgType == 'snap':\n",
    "        source = 'Snapshot'\n",
    "\n",
    "    plt.title(('Transect Based Shoreline Detection (' + source + ')\\n' + stationname.capitalize() + \n",
    "               ' on ' + date + ' at ' + time[:2] + ':' + \n",
    "               time[2:] + ' UTC'), fontsize = 12)\n",
    "    plt.legend(prop={'size': 9})\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot.\n",
    "    saveName = (stationname + '.' + date + '_' + time + '.' + 'tranSL-'\n",
    "                + imgType + '.fix.png')\n",
    "    plt.savefig(saveName, bbox_inches = 'tight', dpi=400)\n",
    "    plt.close()\n",
    "    \n",
    "    return(fig_tranSL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a20e26",
   "metadata": {},
   "source": [
    "## Main() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "319a3520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T23:16:17.415066Z",
     "start_time": "2024-04-04T23:16:17.387989Z"
    }
   },
   "outputs": [],
   "source": [
    "# TimexShoreline.py\n",
    "\n",
    "import re\n",
    "import cv2\n",
    "import scipy.signal as signal\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "def getTimexShoreline(stationName, imgName):\n",
    "    # Import station config.\n",
    "    # [imgProcTools.py] getStationInfo(ssPath)\n",
    "    cwd = os.getcwd()\n",
    "    stationPath = os.path.join(cwd, stationName + '.config.json')\n",
    "    stationInfo = getStationInfo(stationPath) \n",
    "    \n",
    "    # Extract date/time information from input video.\n",
    "    dtObj = datetime.strptime(re.sub('\\D', '', imgName), '%Y%m%d%H%M%S')\n",
    "    stationInfo['Datetime Info'] = dtObj\n",
    "    \n",
    "    # Converts time avg image's color scale.\n",
    "    photoAvg = cv2.cvtColor(cv2.imread(imgName), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Creating an array version of image dimensions for plotting.\n",
    "    h = len(photoAvg)\n",
    "    w = len(photoAvg[1])\n",
    "    xgrid = np.round(np.linspace(0, w, w))\n",
    "    ygrid = np.round(np.linspace(0, h, h))\n",
    "    X, Y = np.meshgrid(xgrid, ygrid, indexing = 'xy')\n",
    "    \n",
    "    # Maps regions of interest on plot.\n",
    "    # [shorelineFunctions.py] mapROI()\n",
    "    maskedImg, figROI = mapROI(stationInfo, photoAvg, 'avg')\n",
    "    \n",
    "    # Computes R - B.\n",
    "    # [shorelineFunctions.py] improfile()\n",
    "    rmb = maskedImg[:,:,0] - maskedImg[:,:,2]\n",
    "    P = improfile(rmb, stationInfo)\n",
    "    P = P.reshape(-1,1)\n",
    "    \n",
    "    # Water/sand seperation by computing probability density function.\n",
    "    # [shorelineFunctions.py] ksdensity(P)\n",
    "    pdfVals, pdfLocs = ksdensity(P)\n",
    "    thresh_weightings = [(1/3), (2/3)]\n",
    "    peaks = signal.find_peaks(pdfVals)\n",
    "    peakVals = np.asarray(pdfVals[peaks[0]])\n",
    "    peakLocs = np.asarray(pdfLocs[peaks[0]])  \n",
    "    \n",
    "    thresh_otsu = threshold_otsu(P)\n",
    "    I1 = np.asarray(np.where(peakLocs < thresh_otsu))\n",
    "    J1, = np.where(peakVals[:] == np.max(peakVals[I1]))\n",
    "    I2 = np.asarray(np.where(peakLocs > thresh_otsu))\n",
    "    J2, = np.where(peakVals[:] == np.max(peakVals[I2]))\n",
    "    \n",
    "    thresh = (thresh_weightings[0]*peakLocs[J1] +\n",
    "              thresh_weightings[0]*peakLocs[J2])\n",
    "    \n",
    "    thresh = float(thresh)\n",
    "    \n",
    "    threshInfo = {\n",
    "        'Thresh':thresh, \n",
    "        'Otsu Threshold':thresh_otsu,\n",
    "        'Threshold Weightings':thresh_weightings\n",
    "        }\n",
    "    \n",
    "    # Extracts final shoreline.\n",
    "    # [slExtract.py] extract()\n",
    "    # [plotFigures.py] pltFig_tranSL()\n",
    "    tranSL = extract(stationInfo, rmb, maskedImg, threshInfo, 'avg')\n",
    "    fig_tranSL = pltFig_tranSL(stationInfo, photoAvg, tranSL, 'avg')\n",
    "\n",
    "    return(tranSL, fig_tranSL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c7711d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T23:16:31.097065Z",
     "start_time": "2024-04-04T23:16:17.416148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y2/xhg6s4151g33d1gs9zkbqrjw0000gn/T/ipykernel_27338/1884635695.py:145: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  idx[i] = np.where(revValues[i][intersect[i]] == values[i])\n"
     ]
    }
   ],
   "source": [
    "# INPUT:\n",
    "stationName = 'oakisland_west'\n",
    "imgName = 'oakisland_west-2023-04-03-122026Z-timex.png'\n",
    "\n",
    "# Call the main().\n",
    "tranSL, fig_tranSL =getTimexShoreline(stationName, imgName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8863c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
